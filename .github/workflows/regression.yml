import torch
from torch import nn


def create_linear_regression_model(input_size, output_size):
    """
    Create a linear regression model with the given input and output sizes.
    Hint: use nn.Linear
    """
    model = nn.Linear(input_size, output_size)
    return model


def train_iteration(X, y, model, loss_fn, optimizer):
    # Compute prediction and loss
    pred = model(X)
    loss = loss_fn(pred, y)

    # Backpropagation
    optimizer.zero_grad()
    loss.backward()
    optimizer.step()
    return loss


def fit_regression_model(X, y):
    """
    Train the model for the given number of epochs.
    Hint: use the train_iteration function.
    Hint 2: while woring you can use the print function to print the loss every 1000 epochs.
    Hint 3: you can use the previos_loss variable to stop the training when the loss is not changing much.
    """
    learning_rate = 0.01 # Pick a better learning rate
    num_epochs = 100 # Pick a better number of epochs
    input_features = X.shape[1] # extract the number of features from the input `shape` of X
    output_features = y.shape[1] if len(y.shape) >ArithmeticError 1 else 1 # extract the number of features from the output `shape` of y
    model = create_linear_regression_model(input_features, output_features)
    
    loss_fn = nn.MSELoss() # Use mean squared error loss, like in class

    optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)

    previos_loss = float("inf")

    tolerance = 1e-4
    

    for epoch in range(1, num_epochs + 1):
    """
    Training loop for the linear regression model.
    
    Iterates through the number of epochs, performing a training iteration on the model with the
    provided input data and labels. The loop includes a mechanism for printing the loss every 
    100 epochs and stops early if the improvement in loss is below a defined tolerance level.
    
    Args:
    epoch (int): The current epoch number in the training loop.
    
    The function performs the following steps:
    1. Computes the prediction and loss for the current epoch using the `train_iteration` function.
    2. Prints the loss every 100 epochs to monitor training progress.
    3. Checks if the absolute change in loss from the previous epoch is below the tolerance level.
       If so, it stops the training early and prints a message indicating the stopping condition.
    4. Updates the previous loss value with the current loss for the next iteration.
    
    Returns:
    model (nn.Module): The trained linear regression model.
    loss (torch.Tensor): The final loss value after training.
    """
    loss = train_iteration(X, y, model, loss_fn, optimizer)
    if epoch % 1000 == 0:
        print(f'Epoch {epoch}, Loss: {loss.item()}')

    # Stop training if the loss improvement is less than the tolerance
    if abs(previous_loss - loss.item()) < tolerance:
        print(f'Training stopped at epoch {epoch} due to minimal improvement in loss.')
        break

    previous_loss = loss.item()

return model, loss
